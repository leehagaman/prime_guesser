{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "\n",
    "from prime_functions import *\n",
    "from llama_prime_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LLama generation, streaming, caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing llama response stream:\n",
      " 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101,"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 17,  19,  23,  29,  31,  37,  41,  43,  47,  53,  59,  61,  67,\n",
       "        71,  73,  79,  83,  89,  97, 101])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'2, 3, 5, 7, 11, 13,'\n",
    "get_llama_primes(prompt, max_output_count=20, print_stream=True, disable_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No llama cache found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  19  23  29  31  37  41  43  47  53  59  61  67  71  73  79  83  89\n",
      "  97 101]\n",
      "[21 23 25 27 29 31 33 35 37 39]\n",
      "[ 17  19  23  29  31  37  41  43  47  53  59  61  67  71  73  79  83  89\n",
      "  97 101]\n",
      "[21 23 25 27 29 31 33 35 37 39]\n",
      "[ 17  19  23  29  31  37  41  43  47  53  59  61  67  71  73  79  83  89\n",
      "  97 101]\n",
      "[21 23 25 27 29 31 33 35 37 39]\n",
      "('2, 3, 5, 7, 11, 13,', 20) : [ 17  19  23  29  31  37  41  43  47  53  59  61  67  71  73  79  83  89\n",
      "  97 101]\n",
      "('13, 17, 19,', 10) : [21 23 25 27 29 31 33 35 37 39]\n"
     ]
    }
   ],
   "source": [
    "prompt1 = '2, 3, 5, 7, 11, 13,'\n",
    "prompt2 = '13, 17, 19,'\n",
    "\n",
    "delete_llama_cache()\n",
    "print_llama_cache()\n",
    "\n",
    "for i in range(3):\n",
    "    print(get_llama_primes(prompt1, max_output_count=20))\n",
    "    print(get_llama_primes(prompt2, max_output_count=10))\n",
    "\n",
    "print_llama_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First N Primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_differences(seed_start_n, seed_end_n, output_count, preprompt=\"\", print_all=False, print_stream=False):\n",
    "\n",
    "    full_primes = nth_prime_list(seed_end_n + output_count)\n",
    "    seed_primes = full_primes[seed_start_n:seed_end_n]\n",
    "\n",
    "    real_primes = full_primes[seed_start_n:]\n",
    "\n",
    "    num_seed_primes = len(seed_primes)\n",
    "    prompt = preprompt + ', '.join([str(p) for p in seed_primes]) + \",\"\n",
    "\n",
    "    llama_primes = get_llama_primes(prompt, max_output_count=output_count, print_stream=print_stream)\n",
    "\n",
    "    if len(llama_primes) < output_count:\n",
    "        llama_primes = np.append(llama_primes, np.full(output_count - len(llama_primes), -1))\n",
    "\n",
    "    llama_primes = np.append(seed_primes, llama_primes)\n",
    "\n",
    "\n",
    "    print(len(llama_primes), len(real_primes))\n",
    "\n",
    "    difference_exists = False\n",
    "    for i in range(num_seed_primes + output_count):\n",
    "        if print_all:\n",
    "            if i < num_seed_primes:\n",
    "                print(i + seed_start_n, real_primes[i], llama_primes[i], \"seed\")\n",
    "            elif real_primes[i] != llama_primes[i]:\n",
    "                print(i + seed_start_n, real_primes[i], llama_primes[i], \"difference!\")\n",
    "            else:\n",
    "                print(i + seed_start_n, real_primes[i], llama_primes[i])\n",
    "        else:\n",
    "            if real_primes[i] != llama_primes[i]:\n",
    "                print(\"difference!\", i, real_primes[i], llama_primes[i])\n",
    "                difference_exists = True\n",
    "\n",
    "    if not print_all and not difference_exists:\n",
    "        print('No differences found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n",
      "0 2 2 seed\n",
      "1 3 3 seed\n",
      "2 5 5 seed\n",
      "3 7 7 seed\n",
      "4 11 11 seed\n",
      "5 13 13 seed\n",
      "6 17 17\n",
      "7 19 19\n",
      "8 23 23\n",
      "9 29 29\n",
      "10 31 31\n",
      "11 37 37\n",
      "12 41 41\n",
      "13 43 43\n",
      "14 47 47\n",
      "15 53 53\n"
     ]
    }
   ],
   "source": [
    "check_for_differences(seed_start_n=0, seed_end_n=6, output_count=10, preprompt=\"\", print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 206\n",
      "difference! 202 1237 1249\n",
      "difference! 203 1249 1259\n",
      "difference! 204 1259 1277\n",
      "difference! 205 1277 1283\n"
     ]
    }
   ],
   "source": [
    "check_for_differences(seed_start_n=0, seed_end_n=6, output_count=200, preprompt=\"\", print_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like llama fails on the 202nd prime, getting the first 202 correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consecutive Primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "180 1087 1087 seed\n",
      "181 1091 1091 seed\n",
      "182 1093 1093 seed\n",
      "183 1097 1097 seed\n",
      "184 1103 1103 seed\n",
      "185 1109 1109 seed\n",
      "186 1117 1117 seed\n",
      "187 1123 1123 seed\n",
      "188 1129 1129 seed\n",
      "189 1151 1151 seed\n",
      "190 1153 1153 seed\n",
      "191 1163 1163 seed\n",
      "192 1171 1171 seed\n",
      "193 1181 1181 seed\n",
      "194 1187 1187 seed\n",
      "195 1193 1117 difference!\n",
      "196 1201 1123 difference!\n",
      "197 1213 1133 difference!\n",
      "198 1217 1139 difference!\n",
      "199 1223 1151 difference!\n",
      "200 1229 1153 difference!\n",
      "201 1231 1163 difference!\n",
      "202 1237 1171 difference!\n",
      "203 1249 1181 difference!\n",
      "204 1259 1187 difference!\n",
      "205 1277 1193 difference!\n",
      "206 1279 1213 difference!\n",
      "207 1283 1217 difference!\n",
      "208 1289 1223 difference!\n",
      "209 1291 1229 difference!\n",
      "210 1297 1231 difference!\n",
      "211 1301 1237 difference!\n",
      "212 1303 1249 difference!\n",
      "213 1307 1259 difference!\n",
      "214 1319 1277 difference!\n"
     ]
    }
   ],
   "source": [
    "check_for_differences(seed_start_n=180, seed_end_n=195, output_count=20, preprompt=\"The following is a list of consecutive primes: \", print_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like llama performs worse starting partway into a list of primes; it's better at recalling given the whole list from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
